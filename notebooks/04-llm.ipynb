{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daf0a90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371780d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hola! Estoy bien, gracias. ¿Y tú? ¿En qué puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "ollama_mml = ChatOllama(model=\"llama3.2\", temperature=0.1)\n",
    "\n",
    "response = ollama_mml.invoke(\"Hola, cómo estás?\")\n",
    "#response.text\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d01f2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Un agente en LangChain es un intermediario que permite a los modelos de lenguaje (como GPT) **actuar de forma autónoma**. Coordina herramientas (bases de datos, APIs, etc.) para ejecutar acciones complejas, tomar decisiones y resolver problemas sin intervención humana directa.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "ollama_deepseek = ChatOllama(\n",
    "    model=\"deepseek-r1:8b\",  # exactamente como aparece en `ollama list`\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "response = ollama_deepseek.invoke(\"Explicame qué es un agente en LangChain en menos de 5 líneas.\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56050263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¡Claro! Aquí te presento 5 ideas de proyectos que puedes realizar utilizando LangChain y Ollama, con diferentes niveles de complejidad:\n",
      "\n",
      "**1. Chatbot de Preguntas y Respuestas sobre un Tema Específico (Nivel Fácil - Intermedio)**\n",
      "\n",
      "* **Concepto:** Crea un chatbot que responda preguntas sobre un tema específico que el usuario elija.\n",
      "* **Tecnología:**\n",
      "    * **Ollama:**  Utiliza un modelo de lenguaje local (como Mistral o Llama 2) para la generación de respuestas.\n",
      "    * **LangChain:**  Crea un \"Chain\" que toma la pregunta del usuario, la pasa al modelo de Ollama, y formatea la respuesta para mostrarla al usuario.\n",
      "* **Ejemplo:** Un chatbot que responda preguntas sobre la historia de Roma, la física cuántica, o la cocina italiana.\n",
      "* **Complejidad:** Fácil - Intermedio (dependiendo de la complejidad de las preguntas y respuestas).\n",
      "* **Beneficios:**  Excelente para aprender los fundamentos de LangChain y Ollama.\n",
      "\n",
      "**2. Generador de Contenido Creativo (Nivel Intermedio)**\n",
      "\n",
      "* **Concepto:**  Un programa que genera diferentes tipos de contenido creativo, como poemas, historias cortas, guiones, o incluso código.\n",
      "* **Tecnología:**\n",
      "    * **Ollama:**  Utiliza un modelo de lenguaje potente (como Mixtral o Llama 2) para la generación.\n",
      "    * **LangChain:**  Crea \"Chains\" que toman prompts (instrucciones) del usuario y los utilizan para guiar la generación de contenido. Puedes experimentar con diferentes \"Templates\" para controlar el formato de la salida.\n",
      "* **Ejemplo:**  \"Escribe un poema sobre el otoño\" o \"Genera un guión corto para una escena de comedia\".\n",
      "* **Complejidad:** Intermedio (requiere experimentar con prompts y \"Templates\").\n",
      "* **Beneficios:**  Permite explorar la creatividad y el control sobre la salida del modelo.\n",
      "\n",
      "**3.  \"Detective de Datos\" con Análisis de Documentos (Nivel Intermedio - Avanzado)**\n",
      "\n",
      "* **Concepto:**  Un programa que analiza documentos (PDFs, textos, etc.) y responde preguntas sobre su contenido.\n",
      "* **Tecnología:**\n",
      "    * **Ollama:**  Utiliza un modelo de lenguaje para la comprensión del lenguaje natural.\n",
      "    * **LangChain:**  Utiliza \"Document Loaders\" para cargar los documentos, \"Text Splitters\" para dividir los documentos en fragmentos manejables, y \"Retrieval Chains\" para buscar información relevante en los documentos y responder preguntas.\n",
      "* **Ejemplo:**  Un programa que responda preguntas sobre un contrato legal, un informe técnico, o un libro.\n",
      "* **Complejidad:** Intermedio - Avanzado (requiere familiarizarse con los componentes de LangChain para el procesamiento de documentos).\n",
      "* **Beneficios:**  Aplicación práctica del \"Retrieval Augmented Generation\" (RAG).\n",
      "\n",
      "**4.  \"Agente\" de Automatización de Tareas (Nivel Avanzado)**\n",
      "\n",
      "* **Concepto:**  Crea un agente que pueda realizar tareas complejas, como reservar vuelos, enviar correos electrónicos, o incluso interactuar con APIs externas.\n",
      "* **Tecnología:**\n",
      "    * **Ollama:**  Utiliza un modelo de lenguaje para la comprensión del lenguaje natural y la generación de respuestas.\n",
      "    * **LangChain:**  Utiliza \"Agents\" para que el agente pueda decidir qué acciones tomar en función de la entrada del usuario.  Puedes integrar herramientas externas (como Google Search o Wolfram Alpha) para ampliar las capacidades del agente.\n",
      "* **Ejemplo:**  Un agente que pueda reservar un vuelo y un hotel, enviando correos electrónicos de confirmación.\n",
      "* **Complejidad:** Avanzado (requiere un conocimiento profundo de LangChain y la capacidad de integrar herramientas externas).\n",
      "* **Beneficios:**  Permite crear aplicaciones de IA más sofisticadas y versátiles.\n",
      "\n",
      "**5.  \"Juego de Preguntas y Respuestas\" con un Modelo Local (Nivel Intermedio)**\n",
      "\n",
      "* **Concepto:**  Crea un juego interactivo donde el usuario hace preguntas y el modelo responde.\n",
      "* **Tecnología:**\n",
      "    * **Ollama:**  Utiliza un modelo de lenguaje para responder preguntas.\n",
      "    * **LangChain:**  Crea \"Chains\" que gestionan el flujo del juego, incluyendo la presentación de preguntas, la recepción de respuestas del usuario, y la evaluación de las respuestas.\n",
      "* **Ejemplo:**  Un juego de trivia sobre historia, ciencia, o cultura general.\n",
      "* **Complejidad:** Intermedio (requiere diseñar la lógica del juego y la interacción con el usuario).\n",
      "* **Beneficios:**  Una forma divertida de aprender y experimentar con LangChain y Ollama.\n",
      "\n",
      "**Recursos Adicionales:**\n",
      "\n",
      "* **Documentación de LangChain:** [https://python.langchain.com/](https://python.langchain.com/)\n",
      "* **Documentación de Ollama:** [https://ollama.com/](https://ollama.com/)\n",
      "* **Tutoriales y Ejemplos de LangChain:** [https://www.langchain.com/tutorials](https://www.langchain.com/tutorials)\n",
      "\n",
      "Espero que estas ideas te sirvan de inspiración. ¡Mucha suerte con tus proyectos!  Si tienes alguna pregunta, no dudes en consultarme.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "gemma_llm = ChatOllama(\n",
    "    model=\"gemma3:4b\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "gemma_llm.invoke(\"Dame 5 ideas de proyectos con LangChain y Ollama.\").pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2e5c6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "No te lo dije antes... Me llamo Asistente, soy un programa de inteligencia artificial diseñado para ayudarte con cualquier cosa que necesites. ¿En qué puedo ayudarte hoy, Juan?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "msg_1 = SystemMessage(content=\"Eres un asistente útil que habla en español.\")\n",
    "# o simplemente: msg_1 = SystemMessage(\"Eres un asistente útil que habla en español.\")\n",
    "\n",
    "msg_2 = HumanMessage(content=\"Me llamo Juan\")\n",
    "msg_3 = AIMessage(content=\"Hola Juan, ¿cómo estás?\")\n",
    "msg_4 = HumanMessage(content=\"¿Cómo me llamo?\")\n",
    "\n",
    "history = [msg_1, msg_2, msg_3, msg_4]\n",
    "\n",
    "response = ollama_mml.invoke(history)\n",
    "response.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5969c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Juan, tu nombre es Juan. ¿En qué puedo ayudarte?\n"
     ]
    }
   ],
   "source": [
    "#esta es la forma compacta o simplificada para los agentes que comparten mismos parametros\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "#en este caso que el modelo de deepseek es local y el provedor es ollama debo agregarle el parametro \"model provider=\"ollama\"\"\n",
    "llm = init_chat_model(model=\"deepseek-r1:8b\", model_provider=\"ollama\", temperature=0)\n",
    "response = llm.invoke(history)\n",
    "response.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (crear-agentes-ai)",
   "language": "python",
   "name": "crear-agentes-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
